* i think the existence of compat_src_indices means that we can be smarter
  about IndexStates list/index allocation? to eliminate (known) incompatible
  indices from the list? 

* see if i can get rid of that num_list_indices in StreamData while i'm at it

* OR kernel
  * DONE rip OR-compat checking out of xor-kernel.
  * DONE generate out.xor output for 4 input variations (2,2, 2,10)(--xor, --xor + --or)
  * DONE verify xor + or matches xor, and both match out.orig.xor
  * DONE commit? on a branch?
  * DONE remove "xor" from name of filter task wrapper functions i think.
  * IN PROGESS figure out where i'm going to plug in the OR kernel execution.
  * DONE make sure sources are already allocated at that spot, if not, move
    allocation to correct spot.
  * IN PROGRESS SORTA write new OR kernel
  * ??
  * PROFIT

* shoud display max variation count (sentence with max # of variations)
  on load, and assert if > whatever limit i temporarily impose for XOR/OR
  combo_idx compatibility (128 for example). can always increase the limit
  later. 64-bits (8 bytes) gets me 128 variation max. 18 bytes (9 x 16-bit)
  gets me 65535 which is variation_t and as high as it'll ever need to go.

* i need to know candidate sources count because I'm going to re-write the
  OR compatibility kernel, and similar to how (iirc) the XOR kernel uses
  one block per "source" then one thread per xor-source, i'm going to want
  to probably use one block per "source" and one thread per or_source.
  (or maybe reverse that, not sure). I'm really not sure what I was thinking
  to be honest.
  * are the candidate sources already copied to the kernel? is that done in
    one of the xor_kernel_task functions? probably I'll need to move that out
    to filter_candidates_cuda or something, or (yet another) intermediate
    wrapper function around the whole filter mess, that wraps both XOR and OR
    filter kernel tasks.

* I want to know how many candidates (and sources) are considered (log message).
  from c++ probably better as that whole JS loop should move to c++.
  * DONE - a little better now. could still count & save the number of "consider"
    calls that were made. that info is getting lost.
  * DONE - for incompatible. along with the # of considered sources that are
    a) duplicate, b) incompatible, c) both - but both is just an internal
    optimization, ultimately "incompatible" wins. and i'm not sure duplicate
    is more than an implementation detail either.
  * need to VERIFY counts are accurate and actually display them somewhere.

* std::move into promise in filter-support

* my understanding of std::move might have regressed for non-initializing 
  assignment of a variable to a function that returns by value. i think i
  need move in those cases, and I think I removed some recently.
  * good testcase for moveable repo
* try adding testcase to moveable repo for return optional<pair<obj,obj>>

* cuda_device_ptr_t

* set --max-sources to N(-1) (if not otherwise specified) when -cM,N ?

* make -t x,y,z show VALID entries even if they exceed max_sources (maybe
  separated by a -- line)

* i need --ccc to run through the same centralized logic as validator to
  determine if an NC can be assigned to the combination of two sources.
  currently that's just "is the NC name the same as a source name" but that
  may change at some point, and I want it to change for everything when it
  does.
  * i think i determined this is bogus? every source saved (in, e.g., a
    knownSourceMap src-list) and associated with a particular name, has
    already been determined to be compatible with that name. all i'm
    doing is adding additional names to sources that were already deemed
    compatible with those names elsewhere. (I think!). If I'm wrong,
    validator will let me know (hasn't happened yet).

* would be nice if -t showed NCs: PRESENT as word:1,word:2 - ..

* clue-manager::add_compound_clue could maybe be integrated into validateSources
  workflow (in index.cpp) depending on conditionals used in TS.

* removed edward,tattoo,wallet =throat and =bomb. (??)

* one of the reasons why the Peco approach is slower, for compatibility
  checking, especially with length > 2, is that once we determine that the
  sources at the current indices of 0 and 1 are incompatible, there is no
  need to test that combination with any other sources from index 2.
  this may be relevant to --ccc speed.

// ++ Tricky Bidness

* SOLVED (i think)
  tricky situation that should be fixed (and in general, beyond this specific
  tricky instance). blue is a synonym of navy in clues 1. we later go on to
  derive "navy" as a solution to "dark,blue".  but if the source of the "blue"
  in this case is the synonym of navy, it should not be allowed.

* SOLVED (i think)
  similarly, validateSources(name) -- enforce everywhere, for below
  validatesources is apparently happy with old:3=not:1,not:1,old:1
  which is wrong because:

* NOT RESOLVED (but solveable, when i make up my mind)
  * same: polar,bear -> white,bear + bear = bad?
  * NOTE that the polar,bear problem is actually different. we're not giving
    a clue a name that is the same as one of its sources there. we're just
    combining two clues (polar, bear), and one of the clues (polar) has bear
    as a source. while I would *like* to disallow this, I can't be certain
    that this isn't allowed.
  * there's definitely an argument to be made that merging a single NC with a 
    name that is the same as a source of another NC is qualitatively different
    than merging two NCs that have a common source name.

// -- Tricky Bidness

* Precompute is taking longer now with -c2,2 and multiple --xors, did I introduce
  some copying?
  - nope, problem is combo indices. 11 million of them. multiply x 9 x 8 (72) and
    that's how many variation indices we allocate (850MB).
  - we could cut that about in half by only copying the 64-bit combo indices once -
    that's 11M * 8 bytes = 88MB. then 11M * 9 sentences = ~100M x 4-byte indices.
    total: 488MB.
  - at some point, i'll probably see 100M combo indices (800MB) + 900M x 4-byte (3.6B)
    = ~4.5GB just for variation indices!

* index.cpp:  merge-only=true is used for showComponents() and consistencyCheck V1,
  both of which can be eliminated.

* on the subject of MFD device memory, we can't free it until a kernel is complete.
  and we can't *reallocate* it (technically) until the kernel has been launched,
  for async kernels, at least (like xor_filter). binary semaphore might work for
  that case: call std::async with a semaphore, release it after kernel launch.

* for MFD-host memory, we can't really reallocate that until after the kernel
  is launched as well (or after a cudaStreamSynchronize prior to kernel launch)
  because we need to make sure it sticks around for any pending async copies.

* while i don't love the idea, it seems like it'd be a lot cleaner to have the
  kernel-launch wrapper code responsible for free'ing device memory. like, we
  typically have to sync to copy results, why not just free stuff then?
  ** OR, instead of calling launch wrapper function directly, call from within
     a lambda that does the freeing afterwards, to keep the alloc/frees a bit
      more local to each other.
  
* Timer.pretty() - get nanoseconds() and auto determine best unit and suffix

* LogDuration: merge_support.cpp, may also want version that uses a CudaEvent/thread
  to synchronize on

* TODO: grep for: FIXMENOW

* display xor_src_lists and xor_sources in normal output, maybe also,
  "compatible" xor_sources, if that means anything, or post-merged count,
  or something.

* don't use the same result buffer for multiple streams. maybe make it part
  of the StreamData struct?

* is_source_OR_compatible kernel function:
  We're doing some pretty rudimentary check to ensure that at least one source from
  each or_arg is compatible, but what if different args refer to the same sentence,
  and the compatible source found for each arg have different variations? maybe I
  can write a test case to demonstrate this, and see what should happen.

* another thought about OR compatibility.  I determine if a particular source is
  XOR compatible with an XorSource then I test if it is OR compatible with at least
  one source of each OR arg.  But shouldn't I also check if the XOR source it was XOR
  compatible with, is also OR-compatible with the candidate OR source?
  * No. OR arg sources don't need to be tested vs. XOR arg sources.

* is_source_XOR_and_OR_compatible:
  so i'm wondering, once one thread determines that it's (both XOR and) OR compatible,
  couldn't I short-circuit the rest of the kernel? like, after the __synchtreads()
  call at the beginning of the loop, if (is_or_compat) break; ? and I could get
  rid of the return true inside the loop, and return is_or_compat; at the end of the
  function?
  This approach (if it works) might apply to other is_xxx_compat functions as well.

* fix variable names in filter-support::cuda_allocCopySentenceVariationIndices()

// CM:

* cm: shouldn't i filter out retired pairs in pairs(.sh) ?
  * and for that matter, would a filter-retired(.sh) script be useful for
    per-letter pairs?
  * maybe i should make cm pairs -l the per-letter pair option, and -c
    the "show letter counts" option
    * reasoning: it will be useful to have a general-purpose script for
      generating per-letter pairs.  -l would take a required argument
      (a single letter, at least in initial implementation)
* cm: ensure words.json is sorted

// ++NEWPERF:

* had an idea about doubling the stride in streamswarm/indexstates if the
  moving average was 0. i could store 3x 10 bit (1024) kernel-time ms values
  in a 32-bit word and <<10 out the oldest and add on the (newest&1023)>>20.
  so after 3 streams if that value (or the moving average of them) is zero,
  double the stride. actually make sure i have accurate timings on all of
  (fill + copy + copy + update). kernel runtime should be greater than sum
  of all of those. i suppose i could store last 3 values for the sum of all
  of those and calculate the moving average of that as well.

* copy/process combo indices is slowwwww. i wonder how much of that is due
  to vector reallocation & copying. maybe i could have a vector of vectors,
  and process, say, ~100k (800KB) indices at a time, then when it fills,
  just push_back another vector?
  * looks like not the case. just a huge amount of memory being copied.

* assigning unique numbers to source/clue names would speed up validator. and
  would consume less memory. could potentially integrate that into ncList/
  primaryNameSrcList as well.

// --NEWPERF

++PERF

* elimination of event sync'ing by storing of host-side data in MFD during copies.
  * deletion of appropriate host data after launch of associated kernel.
  * maybe a "host.merge" and "host.filter" section of MFD, though that may not
    be granular enough. may need a section for every kernel?

* move remaining combo-maker TS code to C++.

* spawn a thread to do "synchronous" sum=2, but acquire a binary semaphore to
  prevent the next sum from executing until all the data from 2 is packed into MFD.

* potentially hairy: see if it's possible to process sources in chunks, such that
  device-data requirements are restricted to some threshold such as 1GB, for sums
  that have lots of sources (such as 19, 20 currently, but this may become a much
  more common problem.)
  * may also want to look at MemPool stuff so I have a bit more control over memory
    and can eliminate the possibility of managed memory being silently allocated.
  * this may also involve a way to accurately compute the total amount of device
    memory used, so I can determine how many "chunks" can run. maybe a chunk is
    100-256MB or something.
  * may also want to do more work to ensure device memory really is all in one
    flat chunk of contiguous memory, rather than a small chunk for indexes, a
    small chunk for sizes, etc. so that "free memory" accurately reflects the
    kind of contiguous chunks that can be loaded. or maybe i can just rely on
    memalloc failing, at least as a first pass, assuming that i can stop managed
    memory from being silently allocated.
  * ultimately i think i'm looking for an abstraction here, that contains the
    host-memory, and "contiains" (or points to) the device memory, for each
    kernel. it can know the total amount of device memory required, take care of
    freeing host (and device if appropriate) memory after launch, etc.

* another possible solution to device-side memory as # of combinations increases,
  is to find out what kind of reduction we'd see if sources were pre-processed
  such that any two sources that have the same source bits and differ only by
  variations, are linked, and only the variation change(s), at 32bits each
  (sentence:16,variation:16) are tagged on to the source. currently a source
  is 9*4 bytes (sourcebits) + 9*2 bytes (variation) = 54 bytes. this would reduce
  nearly-matching sources to (as low as) 6 bytes (incuding 2 bytes for # of different
  sentence/varation pairs). i'm using 2bytes for pair count and sentence index
  because of what I assume is an alignment requirement.
  * could write a kernel to assess the potential savings achievable here, by
    comparing every source (bits) to each other and storing the first bits-compatible
    source in a 32bit output-word.
  * ultimately this would have to be done host-side though, right? because, device
    memory. so maybe just write it host-side. if there's a real benefit, maybe
    consider_candidate() could add to a queue and be processed by a thread(pool)
    to do the check as they are inserted.

* I think there's still potentially some optimization opportunity in xor_kernel by
  shoving some of the read-only data into constant memory, if there's enough room
  (like, source indices, list sizes, even the source descriptor, which are tiny).


--PERF

* I should maybe think about how to introduce an "ignore" letter into a combination
  specifically for sentence 7, if i could just ignore [s] or make (s) optional or
  something.

* fix lifetime issue requiring sync in cuda_allocCopySentenceVariationIndices()
  * store in MFD.

* thoughts from last night: i really want to focus on new sentence combinations, and
  corresponding compound clues in the sub-10 (typically 6-8) region. then combine
  those to build larger combinations. so, performance (and memory use) of large
  compound clues like 19,20 shouldn't really be relevant for the "important" work.
  but I still need to make sure I can load those in at runtime to build XorSources
  (which I am currently doing anyway, up to 20).

* think about if there is some way to specify an "old combinations" string in a
  sentence.json file, and maintain the corresponding compound clues that use that
  combination, but don't actually use that combination in combo-maker.
  * this would include:
    * syntactically, some way to mark it in the sentence.json. like a "skip" flag
      or maybe a priority value, and default priority could be 1, but a command
      line flag could increase it.

    * some way to mark the variations created from that combination with the 
      corresponding priority.
    * combo-maker awareness of current priority, and exclusion of combinations
      containing variations of lower than current priority.

* return CudaEvent (stop) from run_xxx_kernel functions. then we maybe don't need
  the stop_event in StreamData? maybe not though.

* sync on an event whenever i get kernel results. like.. in cuda_copy_results?
  and elsewhere maybe

* kernel timing from @nightchild:
  also nvidia-smi -i 0 -pm 1 will give more reproduce-able results cause it will 
  force a fixed clock

* filer_support::get_incompatible_sources looks wrong. i'm leaving it wrong for now
  because it helps confirm before/after counts, even if the counts are wrong.

* old-working compatible sources and working compatible sources are different.
  why? is it related to above?

* I may need to re-think OR compatibility. Since it's using IsCompatibleSubsetOf
  now. Is that really appropriate for the OR = (XOR || AND) case?

* memory usage (both host and GPU) is a concern with 2,20, probable cause for a big
  slowdown. "shared" GPU memory usage is increasing as dedicated GPU memory appears
  to be capped. driver magic? probably want to consider only running ~5 or so tasks
  simultaneously.

* -t braves,ace ?
  
* add syn/hom of anagrams at .. post-process?
  * so i had a thought about this. if i do -t <primary-src> i probably want to see
    name variations there don't i?  I mean, why not. which means i'd need to duplicate
    (or have a second use for) the effort of doing all of this name-variation post-
    processing, for show-components. it seems, instead, that i can pre-compute the
    map for this. run successive passes through all variation categories, looking
    for matches, and when a pass through all of them yield no new results, we're done.
    that map can be used for lookup by both combo-maker and show-components.

* shouldn't I be using a uint64_t for combo_idx in filter kernel? maybe not? look at
  what these things are host-side and how/where I am copying them to device_side.
  * the problem is that i am using "combo_idx" to mean different things depending on
    the context. in at least one function, i use both "compat_idx" and "combo_idx"
    to refer to the same thing.

* i should probably document and/or name and/or encapsulate some of the clue-manager
  global data into classes to help me remember what is what and what goes where. its
  a bit of a mess of rather poorly named global data and functions at the moment,
  and i don't have a lot of intuition about it all, so could use the help of some
  additional structure.

* getUniqueClueNameCount -> Native.get_num_unique_clue_names

* hash/is_equal for NameCount, make (nc)knownSrcListMap key a NameCount

* reverse-validate components, syns, ans, homs, make sure the keys of these objects
  actually exist in one of the variations? After the variations have been generated,
  in case they're a syn/an/hom of a component variation, for example.

* merge_support: uint64_t num_combos{200'000'000}; // hard-coded chunk size
   should probably (eventually) figure out:
   - hardcoded:
   - GD = goal duration (ms) per chunk (e.g. 50ms)
   - CS = combos per SM that can be done in GD (e.g. 20M)
   - MB = max bytes, to limit on-device memory (e.g. 1GB) 
   - calculated:
   - MC = max combos that can be done in GD: (CS * num_sm), (e.g. 200M for 10sm, 1B for 50sm)
   * I may also want to eventually divide MB by StreamCount and use multiple streams.
* Optimizing merge/get_compat_combos. 200M combos currently, and no streams.
  Low reward atm, but eventually might make sense.
  * 200M kernel finishes in ~35ms, which DOES NOT give us enough time to do
    all the things we want, when interleaving streams:
    * copy results from device (~10ms)
    * iterate results and append indices to "hit indices" list. (~135ms)
    * mayyybe do some source-merging on CPU. not sure. very possibly though,
      given that the #of hits is a overall a very small (??ms)
  * it seems like a decent sized chunk of device memory to alloc/copy, esp
    if there are multiple streams (x2, x3 that amount).

* synonyms need to be global. probably all of them. global hash map.
  this will reduce load time and merge time. not 100% sure how to go about
  implementing though. but should figure it out.

* no --xor == no filter call?  it's crashing due to empty xor data probably
  (but probably shouldn't even be called)
  what about --or with no --xor? bet that's fun. probably should fail (or fix).

* can i sort sources within each device_sources list, in order of the smallest
  xor_sources IndexSpanPair they will test against? like, could I store
  candidates in an ordered set, with a test for the smallest IndexSpanPair
  combined size in the comparator function? or, is a candidate a sourcelist
  already? or just a single source?

* have a stream keep track of how many times it's been run, and/or a total
  count of the number of indices it's processed, then total all of them at
  the end, so i show: num streams executed (M), num indices processed (N)

**************************************************************************
* how about I actually compare new code results with old code results?
  like, cuda-xor. but I need to remove the xorSourceList wrapping from that.
  once that's done, I can remove a big paragraph below about wrapping.
**************************************************************************

* consider stripping some types out of combo_maker.h into separate files.

**************************************************************************
* i have count(), countIndices(), and sum_sizes() and I think they all do 
  the same thing or close to it.  maybe a util.h?
  sum_vector_sizes()/sum_container_sizes()?
  add vec_product, vec_to_string, etc.
**************************************************************************
  
* get rid of std::async? have 1 thread waiting on queue, executing filters,
  and main thread just adds execute requests to queue?
  * async, while a sloppy approach, does appear to be reasonably performant.
    so, the goal here would be to play with more advanced thread management
    such as a single worker thread and a locking queue, and maybe some other
    synchronization primitives, just for the sake of using them. performance
    may or may not be any better.
  * wtf_threadpoool!

* WHEN MERGE EXCEEDS UINT64_T: when I get to this point, which will likely
  result from too many --xor args being specified (although could also happen
  from too many sources of a fewer # of --xor args), I can break down the set
  of --xor args into separate chunks, incremented separately (with separate
  indices). for example, I have an array of 8 matrices, I can make that two
  arrays of 4 matrices. the first array will be 0,0,0,0 for a long time, and
  I can just iterate on the 2nd array until it fills up, then increment first
  array to 0,0,0,1 and process second again. given that I will probably end up
  "chunking" this for kernels anyway due to result set size, I could probably
  chunk-run until array 2 reaches capacity, then "increment" array 1 indices
  on CPU, copy them back over to GPU, and run more chunks. It's not *clear*
  that having an all-GPU solution would be a big win, in other words, due to
  result-set size limitations.

* running multiple list_pair_compat kernels in merge stage seems unnecessary;
  i could make that kernel more loopy and handle all list pairs in one call.
  low priority though, as it finishes the current impl in under 25ms.

* I may have figured out what that NO_DUPLICATES thing in peco was all
  about. in cm-precompute.ts fillKnownNcSourceListMapForSum, with sum=2
  we apparently iterate over all 1,1 combinations, including duplicates
  like 'newton:1','newton:1' currently. probably should disable that?
  (it's a tiny fraction of combos so probably not a big deal)
  Haha. This may be what's breaking things right now.

* additional thoughts on optimizaiton:
 - only call addCandidate every 1000+ candidates. maintain a list and
   bulk push them.

* candidates.comboListMap should be a vector. It's not even strictly
  necessary anymore.

* NCData/List -> NcListContainer

* do i need a new variation category, "prefixes", for which we also do
  a syn/hom lookup in post-process? e.g. cogburn -> cog -> tooth.
  the alternative is that "cog" is ... what.. an anagram? and thus we
  do a syn lookup? maybe "anagram" could be generalized? kinda nice to
  have each "rule" encapsulated as a separate variation entry type.

* NameCount.listHasCompatibleSources looks unnecessary, or weird, or both


* OPTIMIZITIONS:

* adding "powerful" to sentence3 components list really caused the number
  of combinations to explode. It's funny that it didn't actually change the
  output, but that's probably due to the xor.req's I used. There is something
  to investigate here and a couple of potential fixes for this:
  * Investigate: am I ensuring that the sentence words + all components
     form a **unique** list? Should be in Sentence.getUniqueComponentNames
     or something.
  * I think there is potential for a filtering step in here somewhere, where,
     for example, I look at all of the NameSrc results for a particular useNC,
     and see what they have in common. I'm just spitballing, but something
     like "well all NcDataCombinations for this NC have *this* and *that*
     source, so lets leave those sourceBits in for the compatibility check,
     but eliminate the words from the combinatorial set, or something.

     - Eh. I don't think i'm on to anything important there either. I mean,
     you either filter *as* you're considering sources to combine, or you
     filter during the combining process *after* you build lists of prospective
     sources to combine (or both). I am not convinced there is anything here
     but probably worth thinking about more.

     - after some more thought, i do think this is worth exploring. probably
     i'll be screwed without some GPU processing, at which point any data
     optimizations will be kind of moot. we'll find out once all clues are
     converted to sentences.

** the below was a pre-cuda optimization idea
* from notepad:  on elimination: this should only be relevant to combo-making.
  once a component word is chosen for a particular sentence, all other
  sententce combinations that do not contain that component word should be
  eliminated.
  "So I'll need to keep copies of the per-sentence combination list (list of
  string sets - the sets themselves need not be copied), so that I can remove
  the incompatible combinations on a per-generated-combo basis."
  * this is a potential real optimization I think, for combo-making. Eliminate
    compares altogether vs. elimination via compare.
  * it seems this may be relevant for --xor validation and precompute as well?
    * DONE: should auto-fail if conflicting --xor's are provided
    * what about --or's? do we need to prune --xor's in that case?)
  * need to iron it out more detail above and implement it.
