* I think opportunity for optimization is running out in mergecompatible. 
  One last thing to try is somehow having mergecompatLists (and perhaps
  getMergeData) take either a MergedSourcesList or a Source.List. Then
  we'd need a variation of mergeSources took either as the first arg as well.

* I really should be working on the uniquePrimaryNames and output post-processing though.

* then -c --or arg support.

* Probaby want to add this to sentence3 components:
   "powerful": [ "powerful", "pure fowl" ]

* so it seems i'm picking up the name variations again in uniquePrimaryNames
  because i'm back to adding them to the nameSources/nameIndices maps. can
  I initialize primary names before I do that?
  This also seems likely related to the weirdness i'm seeing with
  mergeAllCompatible. BTW i should have noticed the name variation issue, as
  the output is the same but I never actually got around to doing variation
  name lookup post processing! (I dont think)

* so If I really want to speed up precompute further, probably I should
  port the whole getCombosForUseNcLists function and dependences (first/next)
  to C++. I could start with just MergeCompatibleSources2 and dependencies
  though. It's curious that didn't speed things up (probably was using older
  version).

* "addon-mode" module return string "Debug" or "Release" for setting addon path

* so there is a problem with "ignore":true clues which depend on clues in "sentences"
  that don't support the ignore flag. this problem will go away when all clues
  are converted to sentences, presumably, but it's giving incorrect results
  as it stands (hobbit,home appear in valid combinations for with xor.req,
  for example, when they should be "used" by "eye").

* -t 20,s or 24,s are valid, shouldn't be. looks like restrictSameClueNumber
  is broke.
  * now it crashes. after putting in support for non-unique legacy clue names
    into the uniquePrimaryClueNames list.
  * so one idea is we could justa call Validator.validateSources(validateAll: false)
    for any supplyed -t (or --xor, --or, etc) combo. If it doesn't pass
    validator, then, duh, it's nto valid. The problem with this is if I want
    to support name:count syntax: Validator doesn't (currently) support it.
  * Maybe the crash on bad combos is something I can live with for now.

* NameCount.listHasCompatibleSources looks unnecessary, or weird, or both

* so, ClueManager.getClueList(1) is the culprit. In every case, I need
  to review what I am doing with the list when I call it with 1.

* -t --verbose

* -t full support, including --add, will be necessary (might be working now)

* I wonder if I am still respecting max in peco, for the cases where that
  makes sense.  did I comment it out, or just allow undefined?

* Precompute is a tiny bit slower now. Maybe because I'm doing too much
  copying in mergeAllCompatibleSources/XorSources? Any way to put a
  stop to that? Like the optimization idea I might have in a comment there,
  using something like a new CombinedSourceRefs data type 

* All of the "getNumPrimarySources()" stuff is a bit weird now isn't it
  I should look into all uses and confirm what it means. And consider
  the "MaxPossiblePrimarySources" case as a possible solution (largest
  sourcelist variation from each sentence).

* USESOURCES_BITSET:

* equal_to is getting called too much with USEDSOURCES_BITSET. this doesn't
  impact combo-maker generation, only precompute.
* i think i'm going to have to use 1 as the first index
  maybe for source "index" within a variation. at least in c++. I should do
  the same with variation. lets me initialize the bitsets to all zero.

* so with 13 bits I can store 8191 (plus 1 "empty") variations
  with 9 * 13 = 117 bits i can store 9 variation values for the 9 sentences
  in a 128-bit bitset.
  rather than unwrapping UsedSources into a similar array of ints in c++,
  unwrap into a 128-bit bitset, with the value shifted left 13 bits for
  each sentence.
  initialize/default each set of sentence-bits to 0x1fff (13 bits on)

* I think the match changed a bit from above.  now i've got multpile
  values (sources really) per sentence (up to 100) but the variation #
  stays the same.
  so still 13 bits for variation#.
  5, 6 or 7 bits for index (32 64 or 128)
  128 = 13 + N * count 
  N = 115 / count
  for N=5, count = 23
  for N=6, count = 19
  for N=7, count = 16
  for N=8, count = 14
  that's how many primary sources from the same sentence can be stored
  in 128 bits.

  128 is the total number of unique sources per sentence. this takes
  into account the fact that we will be supporting different component-name
  sets with completely different names for each sentence, such as between
  v1 and v2 solutions.

  128 is *probably* a safe number but might be limiting at some point,
  so I think increasing it to 256 probably makes sense. That puts a
  wrench in the 128 bit approach however.

  16 (count, above) is the number of unique source "indexes" from a single
  sentence, the combined primary sources of any compound clue/combination,
  that can be stored in 128 bits. I don't think 16 is going to cut it, as
  sentence 4 & 5 already have 22 & 21 primary sources in the v2 solution,
  so that's obviously a constraint I'd like to avoid. Realistically, 32
  will probably be fine.

  So how do we get to support
  * 256 total unique source component indexes per sentence
  * 32 indexes at a time
  
  coocoo idea below. will *not* work for fast xor comparison. need to use bitset.

  well 8 bits for component indexes x 32 indexes = std::array<uint8_t, 32>
  and we could add an extra int for variation (-1 = unset)

  I could also imagine, but don't know if this makes sense, having an
  aggregate data structure with std::array<uint8_t, 32 * 9> (288 bytes) 
  and std::array<int, 9>. two comparisons per call.  look into array comparison.

* the first/next/nextIndex stuff in combo-maker looks sus

* The below might go away in c++ though if I use bitset.
* take a closer look at UsedSources declarations/comparisons in C++. I think
  I have all declarations covered with = { -1 }, but probably makes sense
  for the default constructor to do that. If there were a default constructor,
  which there isn't (that i'm in control of).
  Similarly, the >= 0 or > -1 comparisons should ideally all be in one spot.

* validateSources(name) -- enforce everywhere

validatesources is apparently happy with old:3=not:1,not:1,old:1
which is wrong because:
1) FIXED: two nots from two different variations of sentence three. i though i checked
   for and prevented this with the "candidates" thing somewhere
2) TODO: this is like that weird case with "bird" being the "name" of a clue that had
   "bird" as a source, and that should be disallowed.
   
clues3.json:  { "name": "old",             "src": "new,not" },
