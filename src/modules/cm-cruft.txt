
// TODO: tuple type interface
const minMaxNcListsTupleToNcDataCombinations = (minMaxNcListsTuple: any[]):
    NCDataList[] =>
{
    const minMax = minMaxNcListsTuple[0];
    const ncLists = minMaxNcListsTuple[1] as NameCount.List[];
    return Peco.makeNew({
        listArray: ncLists.map(ncList => [...Array(ncList.length).keys()]), // keys of array are 0..ncList.length
        max: ncLists.reduce((sum, ncList) => sum + ncList.length, 0)        // sum of lengths of nclists
    }).getCombinations().map((indexList: number[]) => {
        let ncData: NCData = {
	    ncList: combinationNcList(indexList, ncLists)
	};
        if (minMax) ncData.synonymMinMax = minMax;
        return ncData;
    });
};

const getCombinationNcDataLists = (useArgsList: string[], hasMinMax?: boolean):
    any =>
{
    Debug(`useArgsList: ${Stringify(useArgsList)}`);
    if (!useArgsList) return [];
    return useArgsList
	.map(useArg => useArgToMinMaxNameListTuple(useArg, hasMinMax))
        .map(minMaxNameListTuple => {
	    return [minMaxNameListTuple[0], nameOrNcStrListToKnownNcLists(minMaxNameListTuple[1])];  // nameOrNcStrList 
	})
        .map(minMaxNcListsTuple => minMaxNcListsTupleToNcDataCombinations(minMaxNcListsTuple)); // knownNcLists
};

// TODO: combinationNcDataListFromNcDataLists
// same as combinationNcDataList but takes NCDataList[]
// instead of NameCount.List[]
const ncDataCombinationsToNcDataList = (indexList: number[],
    ncDataLists: NCDataList[]): NCDataList => 
{
    return indexList.map((ncDataIndex: number, listIndex: number) =>
	ncDataLists[listIndex][ncDataIndex]);
};

// TODO: ncDataListsToNcDataCombinations
// same as combinationsToNcDataLists that takes NCDataList[]
// instead of NameCount.List[]
const ncDataCombinationsToNcDataLists = (combinationNcDataLists: NCDataList[]):
    NCDataList[] =>
{
    Debug(`ncDataCombinationsToNcDataLists() ` +
	`ncDataCombinationLists: ${Stringify(combinationNcDataLists)}`);
    if (listIsEmpty(combinationNcDataLists)) return [ [] ];
    return Peco.makeNew({
        // TODO: List.toIndexList()
        listArray: combinationNcDataLists.map(ncDataList =>
	    [...Array(ncDataList.length).keys()]), // 0..ncDataList.length-1
        // TODO: List.sumOfSublistLengths()
        max: combinationNcDataLists.reduce((sum, ncDataList) =>
	    sum + ncDataList.length, 0) // sum of lengths of ncDataLists
    }).getCombinations().map((indexList: number[]) =>
	ncDataCombinationsToNcDataList(indexList, combinationNcDataLists));
};

// for combining --xor with --xormm
//
const buildCombinedUseNcDataLists = (useArgsList: string[],
    minMaxUseArgsList: string[]): NCDataList[] =>
{
    const standardNcDataLists = getCombinationNcDataLists(useArgsList);
    const minMaxNcDataLists = getCombinationNcDataLists(minMaxUseArgsList, true);
    const combinedNcDataLists = [...standardNcDataLists, ...minMaxNcDataLists];
    // TODO: if (listIsEmpty(combinedNcDataLists)) combinedNcDataLists.push([]);
    const ncDataLists = ncDataCombinationsToNcDataLists(combinedNcDataLists);
    return ncDataLists;
    //.filter((ncDataList: NCDataList) => sumOfNcDataListCounts(ncDataList) <= maxSum);
};

//

// key types:
//{
// A:
//  'jack:3': {             // non-array object value type
//    'card:2': {
// B:
//      'bird:1,red:1': [   // multiple primary NCs with array value type, split them
//        'bird:2,red:8'
//      ]
//    },
//    'face:1': {
// C:
//      'face:1': [         // single primary NC with array value type, ignore
//        'face:10'
//      ]
//    }
//  }
//}
//
//{
// D:
//  'face:1': [              // single top-level primary NC with array value type, allow
//    'face:10'
//  ]
//}
let recursiveAddSrcNcLists = (list: string[], resultMap: any, top = true): string[] => {
    let keys: string[] = _.flatMap(_.keys(resultMap), (key: string) => {
        let val = resultMap[key];
        if (_.isObject(val)) {
            // A: non-array object value type: allow
            if (!_.isArray(val)) return key;
            // split multiple primary NCs into separate keys
            let splitKeys = key.split(',');
            // B: comma separated key with array value type: split; TODO assert primary?
            if (splitKeys.length > 1) return splitKeys;
            // D: single top-level key with array value type: allow; TODO assert primary?
            if (top) {
                return key;
            }
            // C: single nested key with array value type: ignore; TODO assert primary?
        }
        return [];
    });
    if (!_.isEmpty(keys)) {
        // push combined sorted keys for multi-key case
        if (keys.length > 1) {
            let sortedKeys = keys.sort().toString();
            list.push(sortedKeys);
        }
        keys.forEach(key => {
            // push individual keys
            list.push(key);
            let val = resultMap[key];
            if (val && !_.isArray(val)) {
                recursiveAddSrcNcLists(list, val, false);
            }
        });
    }
    return list;
};

// NOTE: resultMap here is a not actually a ResultMap, it's a resultMap.map().
//
function buildSrcNcList (resultMap: Object): string[] {
    return recursiveAddSrcNcLists([], resultMap);
}

// out of bounds
let oob = 0;


/*
// this really could be reduced to "makeSourceNcCsvList"
//
let makeSourceData = (nc: NameCount.Type, validateResult: ValidateResult,
                      orSourcesNcCsvMap?: Map<string, number>): Source.Data => {
*/
    /*
    let sourceNcCsvList;
    if (validateResult.resultMap) {
        sourceNcCsvList = buildSrcNcList(validateResult.resultMap.map());
    } else {
        Assert(validateResult.ncList.length === 1 && validateResult.ncList[0].count === 1, 'wrong assumption');
        sourceNcCsvList = [NameCount.listToString(validateResult.ncList)];
    }
    if (nc.count > 1) {
        sourceNcCsvList.push(NameCount.toString(nc));
    }
    if (orSourcesNcCsvMap) {
        sourceNcCsvList = sourceNcCsvList.filter(ncCsv => orSourcesNcCsvMap.has(ncCsv));
    }
    */
/*
    return {
	primaryNameSrcList: validateResult.nameSrcList,
	sourceBits: validateResult.sourceBits,
	//usedSources: validateResult.usedSources, // TODO?
	usedSources: Sentence.getUsedSources(validateResult.nameSrcList),
	ncList: [nc], // TODO i could try getting rid of "LazySource.nc" and just make this part of LazySouceData
	//synonymCounts: getSynonymCountsForNcAndValidateResult(nc, validateResult),
	//sourceNcCsvList
    };
};
*/


/*
//
// see: showNcLists
let listOfNcListsToString = (listOfNcLists: NameCount.List[]): string => {
    if (!listOfNcLists) return _.toString(listOfNcLists);
    let result = "";
    listOfNcLists.forEach((ncList, index) => {
        if (index > 0) result += ' - ';
        result += NameCount.listToString(ncList);
    });
    return result;
};

//
//
let stringifySourceList = (sourceList: SourceList): string => {
    let result = "[\n";
    let first = true;
    for (let source of sourceList) {
        if (!first) result += ',\n';
        else first = false;
        result += '  {\n';
        result += `    primaryNameSrcList: ${source.primaryNameSrcList}\n`;
        result += `    ncList: ${source.ncList}\n`;
        //result += `    synonymCounts: ${Stringify2(source.synonymCounts)}\n`;
        //result += `    sourcNcCsvList: ${Stringify2(source.sourceNcCsvList)}\n`;
        result += '  }';
    }
    return result + "\n]";
};

function showNcLists (ncLists: NameCount.List[]): string {
    let str = "";
    let first = true;
    for (let ncList of ncLists) {
        if (!first) str += ' - ';
        str += ncList;
        first = false;
    }
    return _.isEmpty(str) ? "[]" : str;
}

//
//
let sourceListToNcList = (sourceList: AnySourceData[]): NameCount.List => {
    return sourceList.reduce((ncList: NameCount.List, source) => {
        ncList.push(...source.ncList);
        return ncList;
    }, []);
};

//
//
let allCountUnique = (ncList: NameCount.List): boolean => {
    let set = new Set<number>();
    for (let nc of ncList) {
        if (set.has(nc.count)) return false;
	set.add(nc.count);
    }
    return true;
};

//
//
let allCountUnique2 = (nameSrcList1: NameCount.List, nameSrcList2: NameCount.List): boolean => {
    let set = new Set<number>();
    for (let nameSrc of nameSrcList1) {
        set.add(nameSrc.count);
    }
    // TODO: some
    for (let nameSrc of nameSrcList2) {
        if (set.has(nameSrc.count)) return false;
    }
    return true;
};
*/

/*
//
//
let countArrayToNumberList = (countArray: CountArray): number[] => {
    let result: number[] = [];
    for (let index = 1; index < countArray.length; ++index) {
	if (countArray[index] === index) {
	    result.push(index);
	}
    }
    return result;
}

// 
//
let anyCountInArray = (ncList: NameCount.List, countArray: CountArray): boolean => {
    return ncList.some(nc => countArray[nc.count] === nc.count);
};

// 
//
let everyCountInArray = (ncList: NameCount.List, countArray: CountArray): boolean => {
    return ncList.every(nc => countArray[nc.count] === nc.count);
};

//
//
let listToCountArray = (ncList: NameCount.List): CountArray => {
    return ncList.reduce((array, nc) => {
        array[nc.count] = nc.count;
        return array;
    }, new Int32Array(ClueManager.getNumPrimarySources()));
};
*/

/*
//
// TODO: ForPrimaryClue
let getPropertyCountsMapForPrimaryNameSrc = (nameSrc: NameCount.Type): Clue.PropertyCounts.Map => {
    return _.find(ClueManager.getClueList(1), {
        name: nameSrc.name,
        src: _.toString(nameSrc.count)
    }).propertyCounts!;
};

//
//
let getPropertyCountsMapForCompoundClue = (clue: Clue.Compound, count: number): Clue.PropertyCounts.Map => {
    return Clue.PropertyCounts.createMapFromClue(_.find(ClueManager.getClueList(count), clue));
};

//
//
let getPropertyCountsMapForValidateResult = (validateResult: ValidateResult): Clue.PropertyCounts.Map => {
    const count = validateResult.nameSrcList.length;
    if (count === 1) {
        // primary clue: propertyCounts map is attached to clue itself
        // TODO: Clue.fromPrimaryNameSrc (): Clue.Primary
        return getPropertyCountsMapForPrimaryNameSrc(validateResult.nameSrcList[0]); // because length is 1
    } else {
        // compound clue: propertyCounts of sources are attached to each ValidateResult
        return validateResult.propertyCounts!;
    }
};

// Return keys of form ['name1:M', 'name2:N'] as array of form ['name1', 'name2'].
// 
let getResultMapTopLevelClueNameList = (resultMap: any): string[] => {
    return Object.keys(resultMap.internal_map)
        .map(nameSrcStr => nameSrcStr.split(':')[0])
};

//
//
let getPropertyCountsMapForNcAndValidateResult = (nc: NameCount.Type,
                                                  validateResult: ValidateResult): Clue.PropertyCounts.Map => {
    Assert(nc.count === validateResult.nameSrcList.length); // a hypothesis
    const count = validateResult.nameSrcList.length;
    const propertyCounts = getPropertyCountsMapForValidateResult(validateResult);

    // For primary clue, there's only one source variation - the source is the source.
    // PropertyCounts are attached to the clue itself, which we get via the validateResult.
    if (count === 1) return propertyCounts;

    // Compound clues may have many source combination variations, and as a result the
    // the propertyCounts "totals" (for the clue itself plus all its sources) are not
    // stored in the clue itself. Instead, we must merge (add) the propertyCounts of a
    // *particular* source (ValidateResult) with those of the clue itself.
    // TODO: Clue.fromNameAndNameSrcList (): Clue.Compound
    // TODO: 
    const clue = {
        name: nc.name,
        src: getResultMapTopLevelClueNameList(validateResult.resultMap).sort().toString()
    };
    //console.error(`clue: ${Clue.toJSON(clue)}, propertyCounts: ${propertyCounts}`);
    return Clue.PropertyCounts.mergeMaps(propertyCounts,
                                         getPropertyCountsMapForCompoundClue(clue, nc.count));
}

//
//
let getSynonymCountsForValidateResult = (validateResult: ValidateResult): Clue.PropertyCounts.Type => {
    return getPropertyCountsMapForValidateResult(validateResult)[Clue.PropertyName.Synonym];
};

// For primary clues, this is just the synonymCounts attached to the clue.
// For compound clues, this is a combination of the synonymCounts attached to the
// clue, and the synonymCounts attached to the sources represented by validateResult.
let getSynonymCountsForNcAndValidateResult = (nc: NameCount.Type,
                                              validateResult: ValidateResult): Clue.PropertyCounts.Type => {
    return getPropertyCountsMapForNcAndValidateResult(nc, validateResult)[Clue.PropertyName.Synonym];
};
*/



/*
let propertyCountsIsInBounds = (propertyCount: Clue.PropertyCounts.Type, minMax: MinMax.Type|undefined): boolean => {
    const total = propertyCount.total;
    return minMax ? (minMax.min <= total) && (total <= minMax.max) : true;
};

let filterPropertyCountsOutOfBounds = (nc: NameCount.Type, result: ValidateResult, args: MergeArgs): boolean => {
    const synonymCounts = getSynonymCountsForNcAndValidateResult(nc, result);
    const inBounds = propertyCountsIsInBounds(synonymCounts, args.synonymMinMax);
    if (!inBounds) oob++;
    return inBounds;
};
*/

/*
let validateSourceBits = (source: SourceData): CountBits.Type => {
    let sourceBits = CountBits.makeNew();
    CountBits.setMany(sourceBits, Sentence.legacySrcList(source.primaryNameSrcList));
    if (!sourceBits.equals(source.sourceBits)) {
	throw new Error("**source bits mismatch**");
    }
    return sourceBits;
};

let validateMergedSourcesBits = (mergedSources: MergedSources,
    lastMergedSource: SourceData | undefined = undefined): void =>
{
    let mergedBits = CountBits.makeNew();
    let ncCsvList: string[] = [];
    for (const source of mergedSources.sourceList) {
	const sourceBits = validateSourceBits(source);
	CountBits.orInPlace(mergedBits, sourceBits);
	ncCsvList.push(NameCount.listToString(source.ncList));
    }
    if (!mergedBits.equals(mergedSources.sourceBits)) {
	console.error(ncCsvList.toString());
	if (lastMergedSource) {
	    console.error(`lastMergedSource, nc(${NameCount.listToString(lastMergedSource.ncList)})` +
		`, primary(${NameCount.listToString(lastMergedSource.primaryNameSrcList)})`);
	}
	console.error(mergedSources.sourceBits.toString());
	console.error(mergedBits.toString());
	throw new Error("**merged bits mismatch**");
    }
};

let validatePrimarySrcBits = (mergedSourcesList: MergedSourcesList) : void => {
    for (const mergedSources of mergedSourcesList) {
	validateMergedSourcesBits(mergedSources);
    }
};
*/

/*
let getSynonymCounts = (sourceList: AnySourceData[]): Clue.PropertyCounts.Type => {
    throw new Error ('not implemented');
    return sourceList.reduce(
        (counts, source) => Clue.PropertyCounts.add(counts, source.synonymCounts),
        Clue.PropertyCounts.empty());
};
                      
let sourceListHasPropertyCountInBounds = (sourceList: AnySourceData[], minMax: MinMax.Type|undefined): boolean => {
    const synonymCounts = getSynonymCounts(sourceList);
    const inBounds = propertyCountsIsInBounds(synonymCounts, minMax);
    if (!inBounds) {
        if (0) {
            console.error(`oob: [${NameCount.listToNameList(sourceListToNcList(sourceList))}]` +
                `, syn-total(${synonymCounts.total})`);
        }
    }
    return inBounds;
};
*/

/*
let getUseNcSourceListMap = (useNcDataLists: NCDataList[],
    mergeArgs: MergeArgs): Map<string, AnySourceData[]> =>
{
    let map = new Map<string, AnySourceData[]>();
    let numNc = 0;
    let begin = new Date();
    for (let useNcDataList of useNcDataLists) {
        for (let useNcData of useNcDataList) {
	    numNc += useNcData.ncList.length;
	    addNcListToSourceListMap(useNcData.ncList, map, mergeArgs);
	}
    }
    let end = new Duration(begin, new Date()).milliseconds;
    console.error(` getUseNcSourceListMap(${PrettyMs(end)}), nc(${numNc}), unique(${map.size}`);
    return map;
};

let getUseSourceLists = (ncDataLists: NCDataList[], args: any): SourceList[] => {
    if (listIsEmpty(ncDataLists) || listIsEmpty(ncDataLists[0])) return [];

    const mergeArgs = { synonymMinMax: args.synonymMinMax };
    const sourceListMap = getUseNcSourceListMap(ncDataLists, mergeArgs);

    let begin = new Date();
    const sourceLists = buildSourceListsForUseNcData(ncDataLists, sourceListMap, mergeArgs);
    let end = new Duration(begin, new Date()).milliseconds;

    let sum = sourceLists.reduce((total, sl) => { return total + sl.length; }, 0);
    console.error(` buildSLforUseNCD(${PrettyMs(end)}), sourceLists(${sum})`);
    return sourceLists;
};

// Here we have 'orSourceLists', created from getUseSourcesList(Op.or).
//
// Generate a sorted ncCsv using the combined NCs of each sources's ncList,
// in each sourceList. Return a map of ncCsvs : [sourceList index(es)].
//
// Exmample sourceList's ncList's, stringified: [ [ b:1, a:2 ], [ c:3, d:4 ] ]
// Flattened ncList, stringified: [ b:1, a:2, c:3, d:4 ]
// sorted ncCsv: 'a:2,b:1,c:3,d:4'
//
// It'd be preferable to embed this ncCsv within each sourceList itself. I'd need to
// wrap it in an object like { sourceList, ncCsv }.
//
// NOTE: not used, but may use something similar at some point. maybe.
//
let buildOrSourceNcCsvMap = (orSourceLists: SourceList[]): SourceNcCsvMap => {
    return orSourceLists.reduce((map: SourceNcCsvMap, sourceList: SourceList, index: number) => {
        const key = NameCount.listToSortedString(_.flatMap(sourceList, source => source.ncList));
        if (!map[key]) map[key] = [];
        map[key].push(index);
        return map;
    }, {});
};
*/

/*
// TODO: function name
//
const mergeCompatibleXorSources = (indexList: number[], sourceLists: SourceList[]): XorSource[] => {
    let compatible = true;

    let sources: SourceList = [];
    let srcSet = new Set<number>();
    
    // TODO: indexList.some()
    for (let [sourceListIndex, sourceIndex] of indexList.entries()) {
        const source = sourceLists[sourceListIndex][sourceIndex];
	if (!NameCount.listAddCountsToSet(source.primaryNameSrcList, srcSet)) {
	    compatible = false;
	    break;
	}
	sources.push(source);
    }
    if (compatible) {
	let primaryNameSrcList: NameCount.List = [];
	let ncList: NameCount.List = [];
	let sourceBits = CountBits.makeNew();
	let usedSources: number[] = [];
	for (let source of sources) {
	    primaryNameSrcList.push(...source.primaryNameSrcList);
	    sourceBits.orInPlace(source.sourceBits);
	    ncList.push(...source.ncList);
	     // TODO: could do this in place, mergeUsedSourcesInPlace
	    usedSources = mergeUsedSources(usedSources, source.usedSources);
	}

        // I feel like this is still valid and worth removing or commenting
        //Assert(!_.isEmpty(primaryNameSrcList), 'empty primaryNameSrcList');
        let result: XorSource = {
            primaryNameSrcList,
            sourceBits,
	    usedSources,
            ncList,
        };
        return [result];
    }
    return [];
};

//
// TODO function name,
let mergeCompatibleXorSourceCombinations = (sourceLists: SourceList[]): XorSource[] => {
    if (listIsEmpty(sourceLists)) return [];
    let begin = new Date();
    const numEmptyLists = listGetNumEmptySublists(sourceLists);
    if (numEmptyLists > 0) {
        // TODO: sometimes a sourceList is empty, like if doing $(cat required) with a
        // low clue count range (e.g. -c2,4). should that even be allowed?
        Assert(false, `numEmpty(${numEmptyLists}), numLists(${sourceLists.length})`);
    }
    let listArray = sourceLists.map(sourceList => [...Array(sourceList.length).keys()]);
    const peco = Peco.makeNew({
        listArray,
        max: 99999
    });
    let combos = 0;
    let sourceList: XorSource[] = [];
    for (let indexList = peco.firstCombination(); indexList; ) {
        const mergedSources: XorSource[] = mergeCompatibleXorSources(indexList, sourceLists);
        sourceList.push(...mergedSources);
	indexList = peco.nextCombination();
	combos += 1;
    }
    let end = new Duration(begin, new Date()).milliseconds;
    console.error(` merge(${PrettyMs(end)}), combos(${combos})`);
    return sourceList;
};
*/

/*
//
//
let isAnyCompatibleOrSourceANDCompatibleWithSource = (
    compatibleSourceList: CompatibleOrSource.Type[],
    source: SourceData): boolean =>
{
    let compatible = false;
    for (let compatibleSource of compatibleSourceList) {
        // this should never happen because AND compatibility should have propagated up to the
        // container level, and we never should have been called if container is compatible.
        // (not so sure about this anymore, see note somewhere else on AND compatibility at
        // container level)
        Assert(!compatibleSource.andCompatible);
	// TODO:
        //compatible = CountBits.every 1 in 2 (compatibleSource.source.sourceBits, primarySrcArray);
        if (compatible) break;
    }
    return compatible;
};

//
//
let isAnyCompatibleOrSourceXORCompatibleWithSource = (
    compatibleSourceList: CompatibleOrSource.Type[],
    source: SourceData): boolean =>
{
    let compatible = false;
    for (let compatibleSource of compatibleSourceList) {
        // skip any sources that were already determined to be XOR incompatible or AND compatible
        // with command-line supplied --xor sources.
        if (!compatibleSource.xorCompatible || compatibleSource.andCompatible) continue;
        compatible = !CountBits.intersects(compatibleSource.source.sourceBits, source.sourceBits);
        if (compatible) break;
    }
    return compatible;
};

// OR == XOR || AND
//
let isSourceCompatibleWithEveryOrSource = (source: SourceData, orSourceList: OrSource[]) : boolean => {
    let compatible = true; // if no --or sources specified, compatible == true
    for (let orSource of orSourceList) {
        // TODO: skip calls to here if container.compatible = true  which may have been
        // determined in Precompute phase @ markAllANDCompatibleOrSources()
        // and skip the XOR check as well in this case.

        // First check for XOR compatibility
        compatible = isAnyCompatibleOrSourceXORCompatibleWithSource(
            orSource.sourceListContainer.compatibleSourceList, source);
        // Any XOR compatible sources, means "OR compatibility" was achieved with this OrSource
        if (compatible) continue;

        // Next check for AND compatibility, our last hope at achieving "OR compatibility"
        compatible = isAnyCompatibleOrSourceANDCompatibleWithSource(
            orSource.sourceListContainer.compatibleSourceList, source);
        if (!compatible) break;
    }
    return compatible;
};
*/

/*
//
//
let filterXorSourcesXORCompatibleWithSource = (xorSourceList: XorSource[], source: SourceData): XorSource[] => {
    let filteredXorSources: XorSource[] = [];
    for (let xorSource of xorSourceList) {
        if (isSourceXORCompatibleWithXorSource(source, xorSource)) {
            filteredXorSources.push(xorSource);
        }
    }
    return filteredXorSources;
};
*/

/*
//
//
let isSourceXORCompatibleWithXorSource = (source: SourceData, xorSource: XorSource): boolean => {
    const compatible = !CountBits.intersects(source.sourceBits, xorSource.sourceBits);
    return compatible;
};
*/

/*
//
//
let isSourceXORCompatibleWithAnyOrSource = (source: SourceData, xorSourceList: XorSource[]): boolean => {
    for (let xorSource of xorSourceList) {
        if (isSourceXORCompatibleWithXorSource(source, xorSource)) {
            return true;
        }
    }
    return false;
};
*/

/*
//
//
let isAnySourceCompatibleWithUseSources = (sourceList: SourceList, pcd: PreComputed.Data): boolean => {
    // TODO: this is why --xor is required with --or. OK for now. Fix later.
    if (listIsEmpty(pcd.useSourceLists.xor)) return true;

    let compatible = false;
    for (let source of sourceList) {
        //const xorSourceList 
	compatible = isSourceXORCompatibleWithAnyXorSource(source, pcd.useSourceLists.xor);
        // if there were --xor sources specified, and none are compatible with the
        // current source, no further compatibility checking is necessary; continue
        // to next source.
        if (!compatible) continue;

	// TODO:
	//compatible = isSourceCompatibleWithEveryOrSource(source, pcd.useSourceLists.orArgDataList);
        if (compatible) break;
    }
    return compatible;
};

//
//
let showBits = (bits: CountBits.Type, xorSourceList: XorSourceList): void => {
    for (let xorSource of xorSourceList) {
        let compatible = !CountBits.intersects(bits, xorSource.sourceBits);
	let bb: CountBits.Type = CountBits.and(bits, xorSource.sourceBits);
	let bbEmpty = bb.isEmpty();
        console.log(`${bits}\n` +
	    `${xorSource.sourceBits}\n` +
	    `${bb}\n` +
	    `------- compatible(${compatible}), empty(${bbEmpty}`);
    }
};

//
//
let showMergedSourcesBits = (mergedSourcesList: MergedSourcesList, xorSourceList: XorSourceList): void => {
    // TODO: this is why --xor is required with --or. OK for now. Fix later.
    if (listIsEmpty(xorSourceList)) return;

    let compatible = false;
    for (let mergedSources of mergedSourcesList) {
	console.log(`###############`);
        //const xorSourceList 
	showBits(mergedSources.sourceBits, xorSourceList);
    }
};

// Here lazySourceList is a list of lazy, i.e., not yet fully initialized source data for
// generated word-pairs (i.e. a "combo").
//
// Fully load the source data for each word, then perform a full merge on those sources.
//
// Return a list of fully merged sources.
//
let loadAndMergeSourceList = (lazySourceList: LazySourceData[], args: MergeArgs): SourceList => {
    let sourceList: SourceList = [];
    for (let lazySource of lazySourceList) {
        Assert(lazySource.ncList.length === 2);
        Assert(lazySource.validateResults.length === 2);
        let sourcesToMerge: AnySourceData[] = []; // TODO: not ideal, would prefer SourceData here
        for (let index = 0; index < 2; ++index) {
            const sourceData = getSourceData(lazySource.ncList[index], lazySource.validateResults[index], false);
            sourcesToMerge.push(sourceData);
        }
        const mergedSource = mergeSources(sourcesToMerge[0], sourcesToMerge[1], false) as SourceData;
        if (1) { // (propertyCountsIsInBounds(mergedSource.synonymCounts, args.synonymMinMax)) {
            sourceList.push(mergedSource);
        }
    }
    return sourceList;
};

//
//
let makeSynonymFilePath = (name: string): string => {
    return Path.format({
        dir: `${DATA_DIR}syns`,
        base: `${name}.json`
    });
};

//
//
let synonymGetNameList = (name: string): string[] => {
    const path = makeSynonymFilePath(name);
    let json;
    let synListData: Synonym.ListData ;
    try {
        json = Fs.readFileSync(path, 'utf8');
        synListData = JSON.parse(json);
    } catch (err: any) {
        if (err.code !== 'ENOENT') {
            console.error(path);
            throw err;
        }
        return [];
    }
    return synListData.ignore ? []
        : synListData.list.filter(synData => !synData.ignore)
            .map(synData => synData.name);
};

// This is designed for purpose at the moment in that it assumes syn-max is at most 1.
// Therefore if synonymCounts.total is already one for the supplied sourceList, allow 
// no synonyms. If synonymCounts.total is zero, allow one.
//
// There are reasons for doing it this way. For one, it's more complicated and requires
// more recordkeeping to consider which of the two combo-word sources that were merged
// together into sourceList, were the source of a synonym total > 1. It could have been
// 1 from each, or 2 from one.
//
// If I'm ever *serious* about playing with syn-max > 1 though, I'll have to fix this.
//
let getSynonymCombos = (nameList: string[], sourceList: SourceList, args: any): string[] => {
    // NOTE: assumes -x2
    Assert(nameList.length === 2);

    // TODO: also check for --synmin/max here. if max = 0, exit.
    if (!args.use_syns) return [];
    const synonymCounts = getSynonymCounts(sourceList);
    // NOTE: assumes --syn-max = 1
    if (synonymCounts.total > 0) return [];

    let combos: string[] = [];
    const minMax = args.synonymMinMax;
    for (let index = 0; index < 2; ++index) {
        const synList = synonymGetNameList(nameList[index]);
        combos.push(...synList
            .map(synonym => [synonym, nameList[1 - index]])   // map to nameList
            .sort()                                           
            .map(nameList => nameList.toString()));           // map to nameCsv
    }
    return combos;
};

let getSynonymCombosForMergedSourcesList = (nameList: string[],
    mergedSourcesList: MergedSourcesList, args: any): string[] => 
{
    // NOTE: assumes -x2
    Assert(nameList.length === 2);

    // TODO: also check for --synmin/max here. if max = 0, exit.
    if (!args.use_syns) return [];
    //const synonymCounts = getSynonymCounts(sourceList);
    // NOTE: assumes --syn-max = 1
    //if (synonymCounts.total > 0) return [];

    let combos: string[] = [];
    const minMax = args.synonymMinMax;
    for (let index = 0; index < 2; ++index) {
        const synList = synonymGetNameList(nameList[index]);
        combos.push(...synList
            .map(synonym => [synonym, nameList[1 - index]])   // map to nameList
            .sort()                                           
            .map(nameList => nameList.toString()));           // map to nameCsv
    }
    return combos;
};
*/


/*
function combinationsToNcLists (combinationNcLists: NameCount.List[]): NameCount.List[] {
    return Peco.makeNew({
        listArray: combinationNcLists.map(ncList =>
	    [...Array(ncList.length).keys()]), // 0..ncList.length-1
        max: combinationNcLists.reduce((sum, ncList) => sum + ncList.length, 0) // sum of lengths of nclists
    }).getCombinations()
        .map((indexList: number[]) => combinationNcList(indexList, combinationNcLists));
}

function buildAllUseNcLists (useArgsList: string[]): NameCount.List[] {
    return combinationsToNcLists(getCombinationNcLists(useArgsList));
}

let sumOfNcDataListCounts = (ncDataList: NCDataList): number => {
    let sum = 0;
    for (let ncData of ncDataList) {
	sum += NameCount.listCountSum(ncData.ncList);
    }
    return sum;
}

let getOrSourcesNcCsvCountMap = (useSourcesList: UseSource[]): Map<string, number> => {
    let map = new Map<string, number>();
    for (let useSource of useSourcesList) {
        if (!useSource.orSource) continue;
        for (let ncCsv of _.keys(useSource.orSource.sourceNcCsvMap)) {
            let value = map.get(ncCsv) || 0;
            map.set(ncCsv, value + 1);
        }
    }
    return map;
};

function buildUseNcLists (useArgsList: string[]): NameCount.List[] {
    let useNcLists: NameCount.List[] = [];
    useArgsList.forEach((useArg: string) =>  {
        let args = useArg.split(',');
        let ncList: NameCount.List = args.map(arg => {
            let nc = NameCount.makeNew(arg);
            Assert(nc.count, `arg: ${arg} requires a :COUNT`);
            Assert(_.has(ClueManager.getKnownClueMap(nc.count), nc.name),
                `arg: ${nc} does not exist`);
            return nc;
        });
        useNcLists.push(ncList);
    });
    return useNcLists;
}

let formatListOfListCounts = (listOfLists: any[][]): string => {
    let total = listOfLists.reduce((sum, list) => {
        sum += list.length;
        return sum;
    }, 0);
    return `(${listOfLists.length}) total(${total})`;
}

let formatListOfNcDataCounts = (ncDataList: NCDataList): string => {
    let total = ncDataList.reduce((sum, ncData) => {
        sum += ncData.ncList.length;
        return sum;
    }, 0);
    return `(${ncDataList.length}) total(${total})`;
}
*/
